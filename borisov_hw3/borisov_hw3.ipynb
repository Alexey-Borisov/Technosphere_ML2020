{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Алгоритмы интеллектуальной обработки больших объемов данных\n",
    "## Домашнее задание №3 - Дерево решений\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Общая информация**\n",
    "\n",
    "**Срок сдачи:** 08 декабря 2020, 08:30   \n",
    "**Штраф за опоздание:** -2 балла после 08:30 08 декабря, -4 балла после 08:30 15 декабря, -6 баллов после 08:30 22 декабря, -8 баллов после 08:30 29 декабря.\n",
    "\n",
    "При отправлении ДЗ указывайте фамилию в названии файла Присылать ДЗ необходимо в виде ссылки на свой github репозиторий на почту ml1.sphere@mail.ru с указанием темы в следующем формате:\n",
    "[ML0220, Задание 3] Фамилия Имя. \n",
    "\n",
    "\n",
    "Используйте данный Ipython Notebook при оформлении домашнего задания."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Реализуем дерево решений (3 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Допишите недостающие части дерева решений. Ваша реализация дерева должна работать по точности не хуже DecisionTreeClassifier из sklearn.\n",
    "Внимание: если Вас не устраивает предложенная структура хранения дерева, Вы без потери баллов можете сделать свой класс DecisionTreeClassifier, в котором сами полностью воспроизведете алгоритм дерева решений. Обязательно в нем иметь только функции fit, predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.model_selection import KFold, train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDecisionTreeClassifier(BaseEstimator):\n",
    "    NON_LEAF_TYPE = 0\n",
    "    LEAF_TYPE = 1\n",
    "\n",
    "    def __init__(self, min_samples_split=2, min_Q_split=0.0001, feature_linspace=20, max_depth=5, criterion='gini'):\n",
    "        \"\"\"\n",
    "        criterion -- критерий расщепления. необходимо релизовать три:\n",
    "        Ошибка классификации, Индекс Джини, Энтропийный критерий\n",
    "        max_depth -- максимальная глубина дерева\n",
    "        min_samples_split -- минимальное число объектов в листе, чтобы сделать новый сплит\n",
    "        \"\"\"\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.min_Q_split = min_Q_split\n",
    "        self.feature_linspace = feature_linspace\n",
    "        self.max_depth = max_depth\n",
    "        self.num_class = -1\n",
    "        # Для последнего задания\n",
    "        self.feature_importances = dict()\n",
    "        \n",
    "        # Сразу определяем нужный критерий информативности\n",
    "        if criterion == 'error':\n",
    "            self.F = error\n",
    "        elif criterion == 'entropy':\n",
    "            self.F = entropy\n",
    "        else:\n",
    "            self.F = gini\n",
    "        # Структура, которая описывает дерево\n",
    "        # Представляет словарь, где для  node_id (айдишник узла дерева) храним\n",
    "        # (тип_узла, айдишник признака сплита, порог сплита) если тип NON_LEAF_TYPE\n",
    "        # (тип_узла, предсказание класса, вероятность класса) если тип LEAF_TYPE\n",
    "        # Подразумевается, что у каждого node_id в дереве слева \n",
    "        # узел с айди 2 * node_id + 1, а справа 2 * node_id + 2\n",
    "        self.tree = dict()\n",
    "\n",
    "    def __div_samples(self, x, y, feature_id, threshold):\n",
    "        \"\"\"\n",
    "        Разделяет объекты на 2 множества\n",
    "        x -- матрица объектов\n",
    "        y -- вектор ответов\n",
    "        feature_id -- айдишник признака, по которому делаем сплит\n",
    "        threshold -- порог, по которому делаем сплит\n",
    "        \"\"\"\n",
    "        left_mask = x[:, feature_id] > threshold\n",
    "        right_mask = ~left_mask\n",
    "        return x[left_mask], x[right_mask], y[left_mask], y[right_mask]\n",
    "    \n",
    "    def __div_samples_only_y(self, x, y, feature_id, threshold):\n",
    "        \"\"\"\n",
    "        Разделяет объекты на 2 множества\n",
    "        x -- матрица объектов\n",
    "        y -- вектор ответов\n",
    "        feature_id -- айдишник признака, по которому делаем сплит\n",
    "        threshold -- порог, по которому делаем сплит\n",
    "        \"\"\"\n",
    "        left_mask = x[:, feature_id] > threshold\n",
    "        right_mask = ~left_mask\n",
    "        return y[left_mask], y[right_mask]\n",
    "\n",
    "    def __find_threshold(self, x, y):\n",
    "        \"\"\"\n",
    "        Находим оптимальный признак и порог для сплита\n",
    "        Здесь используемые разные impurity в зависимости от self.criterion\n",
    "        \"\"\"\n",
    "        max_Q = -np.inf\n",
    "        best_feature = None\n",
    "        best_threshold = None\n",
    "        for feature_id in range(x.shape[1]):\n",
    "            min_val = x[:, feature_id].min()\n",
    "            max_val = x[:, feature_id].max()\n",
    "            thresholds = np.linspace(start=min_val, stop=max_val, num=self.feature_linspace)[:-1]\n",
    "            for threshold in thresholds:\n",
    "                cur_Q = self.Q(x, y, feature_id, threshold)\n",
    "                if cur_Q > max_Q:\n",
    "                    max_Q = cur_Q\n",
    "                    best_feature = feature_id\n",
    "                    best_threshold = threshold\n",
    "        if best_feature not in self.feature_importances:\n",
    "            self.feature_importances[best_feature] = max_Q\n",
    "        else:\n",
    "            self.feature_importances[best_feature] += max_Q\n",
    "        return best_feature, best_threshold, max_Q\n",
    "\n",
    "    def __fit_node(self, x, y, node_id, depth):\n",
    "        \"\"\"\n",
    "        Делаем новый узел в дереве\n",
    "        Решаем, терминальный он или нет\n",
    "        Если нет, то строим левый узел  с айди 2 * node_id + 1\n",
    "        И правый узел с  айди 2 * node_id + 2\n",
    "        \"\"\"\n",
    "        # Проверяем различные критерии останова\n",
    "        if depth <= self.max_depth and x.shape[0] >= self.min_samples_split and np.unique(y).shape[0] != 1:\n",
    "            split_info = self.__find_threshold(x, y)\n",
    "            # При малом максимальном Q делаем вершину листовой\n",
    "            if split_info[2] < self.min_Q_split:\n",
    "                class_distr = np.bincount(y)\n",
    "                most_prob_class = class_distr.argmax()\n",
    "                class_prob = class_distr[most_prob_class] / y.shape[0]\n",
    "                self.tree[node_id] = (self.LEAF_TYPE, most_prob_class, class_prob)\n",
    "                return\n",
    "            self.tree[node_id] = (self.NON_LEAF_TYPE, split_info[0], split_info[1])\n",
    "            div = self.__div_samples(x, y, split_info[0], split_info[1])\n",
    "            self.__fit_node(div[0], div[2], 2 * node_id + 1, depth + 1)\n",
    "            self.__fit_node(div[1], div[3], 2 * node_id + 2, depth + 1)\n",
    "        else:\n",
    "            class_distr = np.bincount(y)\n",
    "            most_prob_class = class_distr.argmax()\n",
    "            class_prob = class_distr[most_prob_class] / y.shape[0]\n",
    "            self.tree[node_id] = (self.LEAF_TYPE, most_prob_class, class_prob)\n",
    "    \n",
    "    def fit(self, x, y):\n",
    "        \"\"\"\n",
    "        Рекурсивно строим дерево решений\n",
    "        Начинаем с корня node_id 0\n",
    "        \"\"\"\n",
    "        self.num_class = np.unique(y).size\n",
    "        self.__fit_node(x, y, 0, 0) \n",
    "\n",
    "    def __predict_class(self, x, node_id):\n",
    "        \"\"\"\n",
    "        Рекурсивно обходим дерево по всем узлам,\n",
    "        пока не дойдем до терминального\n",
    "        \"\"\"\n",
    "        node = self.tree[node_id]\n",
    "        if node[0] == self.__class__.NON_LEAF_TYPE:\n",
    "            _, feature_id, threshold = node\n",
    "            if x[feature_id] > threshold:\n",
    "                return self.__predict_class(x, 2 * node_id + 1)\n",
    "            else:\n",
    "                return self.__predict_class(x, 2 * node_id + 2)\n",
    "        else:\n",
    "            return node[1]\n",
    "        \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Вызывает predict для всех объектов из матрицы X\n",
    "        \"\"\"\n",
    "        return np.array([self.__predict_class(x, 0) for x in X])\n",
    "    \n",
    "    def fit_predict(self, x_train, y_train, predicted_x):\n",
    "        self.fit(x_train, y_train)\n",
    "        return self.predict(predicted_x)\n",
    "    \n",
    "    def get_feature_importance(self):\n",
    "        \"\"\"\n",
    "        Возвращает важность признаков\n",
    "        \"\"\"\n",
    "        values = np.array(list(self.feature_importances.values()))\n",
    "        features = np.array(list(self.feature_importances.keys()))\n",
    "        arg = np.argsort(values)\n",
    "        features = features[arg][::-1]\n",
    "        values = values[arg][::-1]\n",
    "        return features, values\n",
    "    \n",
    "    # Функция считающая критерий информативности\n",
    "    def Q(self, x, y, feature_id, threshold):\n",
    "        div = self.__div_samples_only_y(x, y, feature_id, threshold)\n",
    "        if div[0].shape[0] == 0 or div[1].shape[0] == 0:\n",
    "            return -np.inf\n",
    "        return self.F(y) - div[0].shape[0] / y.shape[0] * self.F(div[0]) - div[1].shape[0] / y.shape[0] * self.F(div[1])\n",
    "\n",
    "# Функции реализующие соответствующие критерии информативности\n",
    "def error(y):\n",
    "    return 1 - np.bincount(y).max() / y.shape[0]\n",
    "\n",
    "def gini(y):\n",
    "    probabilities = np.bincount(y) / y.shape[0]\n",
    "    return 1  - (probabilities**2).sum()\n",
    "\n",
    "def entropy(y):\n",
    "    probabilities = np.bincount(y) / y.shape[0]\n",
    "    probabilities[probabilities == 0] = 0.000001\n",
    "    return -(probabilities * np.log(probabilities)).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_clf = MyDecisionTreeClassifier(min_samples_split=2, min_Q_split=0.16, feature_linspace=4)\n",
    "clf = DecisionTreeClassifier(min_samples_split=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine = load_wine()\n",
    "X_train, X_test, y_train, y_test = train_test_split(wine.data, wine.target, test_size=0.1, stratify=wine.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 612,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_clf.fit(X_train, y_train)\n",
    "clf.fit(X_train, y_train)\n",
    "len(my_clf.tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SKLEARN SCORE: 0.7777777777777778\n",
      "MY SCORE: 0.8333333333333334\n"
     ]
    }
   ],
   "source": [
    "print(\"SKLEARN SCORE:\", accuracy_score(y_pred=clf.predict(X_test), y_true=y_test))\n",
    "print(\"MY SCORE:\", accuracy_score(y_pred=my_clf.predict(X_test), y_true=y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проведу множество испытаний, чтобы убедиться в том, что моя реализация не уступает DecisionTreeClassifier из sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SKLEARN MEAN SCORE: 0.8983333333333333\n",
      "MY MEAN SCORE: 0.901111111111111\n"
     ]
    }
   ],
   "source": [
    "N = 100\n",
    "\n",
    "sklearn_scores = np.zeros(N)\n",
    "my_scores = np.zeros(N)\n",
    "\n",
    "for i in range(N):\n",
    "    my_clf = MyDecisionTreeClassifier(min_samples_split=2, min_Q_split=0.16, feature_linspace=4)\n",
    "    clf = DecisionTreeClassifier(min_samples_split=2)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(wine.data, wine.target, test_size=0.1, stratify=wine.target)\n",
    "    my_clf.fit(X_train, y_train)\n",
    "    clf.fit(X_train, y_train)\n",
    "    sklearn_scores[i] = accuracy_score(y_pred=clf.predict(X_test), y_true=y_test)\n",
    "    my_scores[i] = accuracy_score(y_pred=my_clf.predict(X_test), y_true=y_test)\n",
    "\n",
    "print(\"SKLEARN MEAN SCORE:\", sklearn_scores.mean())\n",
    "print(\"MY MEAN SCORE:\", my_scores.mean())   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ускоряем дерево решений (2 балла)\n",
    "Добиться скорости работы на fit не медленнее чем в 10 раз sklearn на данных wine. \n",
    "Для этого используем numpy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Скорость работы fit'а напрямую зависит от числа вершин в дереве, и в зависимости от числа вершин моя реализация работает в 10-15 раз медленнее sklearn реализации. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 614,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "642 µs ± 3.92 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.75 ms ± 56.4 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit my_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 615,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(my_clf.tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Боевое применение (3 балла)\n",
    "\n",
    "На практике Вы познакомились с датасетом Speed Dating Data. В нем каждая пара в быстрых свиданиях характеризуется определенным набором признаков. Задача -- предсказать, произойдет ли матч пары (колонка match). \n",
    "\n",
    "Пример работы с датасетом можете найти в практике пункт 2\n",
    "https://github.com/VVVikulin/ml1.sphere/blob/master/2019-09/lecture_06/pract-trees.ipynb\n",
    "\n",
    "Данные и описания колонок лежат тут\n",
    "https://cloud.mail.ru/public/8nHV/p6J7wY1y1/speed-dating-experiment/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Скачайте датасет, обработайте данные, как показано на семинаре или своим собственным способом. Обучите дерево классифкации. В качестве таргета возьмите колонку 'match'. Постарайтесь хорошо обработать признаки, чтобы выбить максимальную точность. Если точность будет близка к случайному гаданию, задание не будет защитано. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 647,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Speed Dating Data.csv\", encoding='latin1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Буду добавлять признаки, которые считаю значимыми."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 648,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_df = pd.DataFrame()\n",
    "\n",
    "my_df['iid'] = df.iid.fillna(0)\n",
    "\n",
    "my_df['pid'] = df.pid.fillna(0)\n",
    "\n",
    "my_df['gender'] = df.gender\n",
    "\n",
    "my_df['int_corr'] = df.int_corr.fillna(0)\n",
    "\n",
    "my_df['samerace'] = df.samerace\n",
    "\n",
    "my_df['age'] = df.age.fillna(df.age.mean())\n",
    "\n",
    "my_df['diff_age'] = my_df.age - df.age_o.fillna(df.age.mean())\n",
    "\n",
    "my_df['imprace'] = df.imprace.fillna(df.imprace.mean())\n",
    "\n",
    "my_df['imprelig'] = df.imprelig.fillna(df.imprelig.mean())\n",
    "\n",
    "my_df['date'] = df.date.fillna(df.date.mean())\n",
    "\n",
    "my_df['go_out'] = df.go_out.fillna(df.go_out.mean())\n",
    "\n",
    "my_df['exphappy'] = df.exphappy.fillna(df.exphappy.mean())\n",
    "\n",
    "my_df['dec'] = df.dec\n",
    "\n",
    "my_df['attr'] = df.attr.fillna(df.attr.mean())\n",
    "my_df['sinc'] = df.sinc.fillna(df.sinc.mean())\n",
    "my_df['intel'] = df.intel.fillna(df.intel.mean())\n",
    "my_df['fun'] = df.fun.fillna(df.fun.mean())\n",
    "my_df['amb'] = df.amb.fillna(df.amb.mean())\n",
    "my_df['shar'] = df.shar.fillna(df.shar.mean())\n",
    "my_df['like'] = df.like.fillna(df.like.mean())\n",
    "\n",
    "my_df['prob'] = df.prob.fillna(df.prob.mean())\n",
    "\n",
    "my_df['met'] = df.met.fillna(0)\n",
    "\n",
    "my_df['match_es'] = df.match_es.fillna(0)\n",
    "\n",
    "my_df['satis_2'] = df.satis_2.fillna(df.satis_2.mean())\n",
    "\n",
    "my_df['you_call'] = df.you_call.fillna(df.you_call.mean())\n",
    "\n",
    "my_df['them_cal'] = df.them_cal.fillna(df.them_cal.mean())\n",
    "\n",
    "my_df['target'] = df.match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 649,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iid</th>\n",
       "      <th>pid</th>\n",
       "      <th>gender</th>\n",
       "      <th>int_corr</th>\n",
       "      <th>samerace</th>\n",
       "      <th>age</th>\n",
       "      <th>diff_age</th>\n",
       "      <th>imprace</th>\n",
       "      <th>imprelig</th>\n",
       "      <th>date</th>\n",
       "      <th>...</th>\n",
       "      <th>amb</th>\n",
       "      <th>shar</th>\n",
       "      <th>like</th>\n",
       "      <th>prob</th>\n",
       "      <th>met</th>\n",
       "      <th>match_es</th>\n",
       "      <th>satis_2</th>\n",
       "      <th>you_call</th>\n",
       "      <th>them_cal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.16</td>\n",
       "      <td>1</td>\n",
       "      <td>21.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.207523</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8373</th>\n",
       "      <td>552</td>\n",
       "      <td>526.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.777524</td>\n",
       "      <td>5.474559</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8374</th>\n",
       "      <td>552</td>\n",
       "      <td>527.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.474559</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8375</th>\n",
       "      <td>552</td>\n",
       "      <td>528.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.46</td>\n",
       "      <td>0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>5.474559</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8376</th>\n",
       "      <td>552</td>\n",
       "      <td>529.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.777524</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8377</th>\n",
       "      <td>552</td>\n",
       "      <td>530.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8378 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      iid    pid  gender  int_corr  samerace   age  diff_age  imprace  \\\n",
       "0       1   11.0       0      0.14         0  21.0      -6.0      2.0   \n",
       "1       1   12.0       0      0.54         0  21.0      -1.0      2.0   \n",
       "2       1   13.0       0      0.16         1  21.0      -1.0      2.0   \n",
       "3       1   14.0       0      0.61         0  21.0      -2.0      2.0   \n",
       "4       1   15.0       0      0.21         0  21.0      -3.0      2.0   \n",
       "...   ...    ...     ...       ...       ...   ...       ...      ...   \n",
       "8373  552  526.0       1      0.64         0  25.0      -1.0      1.0   \n",
       "8374  552  527.0       1      0.71         0  25.0       1.0      1.0   \n",
       "8375  552  528.0       1     -0.46         0  25.0      -4.0      1.0   \n",
       "8376  552  529.0       1      0.62         0  25.0       3.0      1.0   \n",
       "8377  552  530.0       1      0.01         0  25.0       3.0      1.0   \n",
       "\n",
       "      imprelig  date  ...       amb      shar  like      prob  met  match_es  \\\n",
       "0          4.0   7.0  ...  6.000000  5.000000   7.0  6.000000  2.0       4.0   \n",
       "1          4.0   7.0  ...  5.000000  6.000000   7.0  5.000000  1.0       4.0   \n",
       "2          4.0   7.0  ...  5.000000  7.000000   7.0  5.207523  1.0       4.0   \n",
       "3          4.0   7.0  ...  6.000000  8.000000   7.0  6.000000  2.0       4.0   \n",
       "4          4.0   7.0  ...  6.000000  6.000000   6.0  6.000000  2.0       4.0   \n",
       "...        ...   ...  ...       ...       ...   ...       ...  ...       ...   \n",
       "8373       1.0   2.0  ...  6.777524  5.474559   2.0  5.000000  0.0       3.0   \n",
       "8374       1.0   2.0  ...  4.000000  5.474559   4.0  4.000000  0.0       3.0   \n",
       "8375       1.0   2.0  ...  8.000000  5.474559   6.0  5.000000  0.0       3.0   \n",
       "8376       1.0   2.0  ...  6.777524  5.000000   5.0  5.000000  0.0       3.0   \n",
       "8377       1.0   2.0  ...  8.000000  1.000000   4.0  5.000000  0.0       3.0   \n",
       "\n",
       "      satis_2  you_call  them_cal  target  \n",
       "0         6.0       1.0       1.0       0  \n",
       "1         6.0       1.0       1.0       0  \n",
       "2         6.0       1.0       1.0       1  \n",
       "3         6.0       1.0       1.0       1  \n",
       "4         6.0       1.0       1.0       1  \n",
       "...       ...       ...       ...     ...  \n",
       "8373      5.0       2.0       0.0       0  \n",
       "8374      5.0       2.0       0.0       0  \n",
       "8375      5.0       2.0       0.0       0  \n",
       "8376      5.0       2.0       0.0       0  \n",
       "8377      5.0       2.0       0.0       0  \n",
       "\n",
       "[8378 rows x 27 columns]"
      ]
     },
     "execution_count": 649,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим отдельно таблицу с мужчинами и женщинами, и сджойним их."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 650,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_male = my_df.query('gender == 1').drop(['gender'], axis=1)\n",
    "df_female = my_df.query('gender == 0').drop(['gender', 'target', 'int_corr', 'samerace', 'diff_age'], axis=1)\n",
    "df_female.columns = df_female.columns + '_f'\n",
    "df_male = df_male.rename(columns={'pid': 'iid_f'})\n",
    "df_female = df_female.rename(columns={'pid_f': 'iid'})\n",
    "df_male = df_male.rename(columns={'target_m': 'target'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 651,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iid</th>\n",
       "      <th>iid_f</th>\n",
       "      <th>int_corr</th>\n",
       "      <th>samerace</th>\n",
       "      <th>age</th>\n",
       "      <th>diff_age</th>\n",
       "      <th>imprace</th>\n",
       "      <th>imprelig</th>\n",
       "      <th>date</th>\n",
       "      <th>go_out</th>\n",
       "      <th>...</th>\n",
       "      <th>fun_f</th>\n",
       "      <th>amb_f</th>\n",
       "      <th>shar_f</th>\n",
       "      <th>like_f</th>\n",
       "      <th>prob_f</th>\n",
       "      <th>met_f</th>\n",
       "      <th>match_es_f</th>\n",
       "      <th>satis_2_f</th>\n",
       "      <th>you_call_f</th>\n",
       "      <th>them_cal_f</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.29</td>\n",
       "      <td>1</td>\n",
       "      <td>27.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-0.24</td>\n",
       "      <td>1</td>\n",
       "      <td>27.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.71151</td>\n",
       "      <td>0.780825</td>\n",
       "      <td>0.981631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-0.18</td>\n",
       "      <td>1</td>\n",
       "      <td>27.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-0.43</td>\n",
       "      <td>1</td>\n",
       "      <td>27.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4179</th>\n",
       "      <td>552</td>\n",
       "      <td>526.0</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4180</th>\n",
       "      <td>552</td>\n",
       "      <td>527.0</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.00000</td>\n",
       "      <td>0.780825</td>\n",
       "      <td>0.981631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4181</th>\n",
       "      <td>552</td>\n",
       "      <td>528.0</td>\n",
       "      <td>-0.46</td>\n",
       "      <td>0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4182</th>\n",
       "      <td>552</td>\n",
       "      <td>529.0</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4183</th>\n",
       "      <td>552</td>\n",
       "      <td>530.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4184 rows × 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      iid  iid_f  int_corr  samerace   age  diff_age  imprace  imprelig  date  \\\n",
       "0      11    1.0      0.14         0  27.0       6.0      7.0       3.0   5.0   \n",
       "1      11    2.0      0.29         1  27.0       3.0      7.0       3.0   5.0   \n",
       "2      11    3.0     -0.24         1  27.0       2.0      7.0       3.0   5.0   \n",
       "3      11    4.0     -0.18         1  27.0       4.0      7.0       3.0   5.0   \n",
       "4      11    5.0     -0.43         1  27.0       6.0      7.0       3.0   5.0   \n",
       "...   ...    ...       ...       ...   ...       ...      ...       ...   ...   \n",
       "4179  552  526.0      0.64         0  25.0      -1.0      1.0       1.0   2.0   \n",
       "4180  552  527.0      0.71         0  25.0       1.0      1.0       1.0   2.0   \n",
       "4181  552  528.0     -0.46         0  25.0      -4.0      1.0       1.0   2.0   \n",
       "4182  552  529.0      0.62         0  25.0       3.0      1.0       1.0   2.0   \n",
       "4183  552  530.0      0.01         0  25.0       3.0      1.0       1.0   2.0   \n",
       "\n",
       "      go_out  ...  fun_f  amb_f  shar_f  like_f  prob_f  met_f  match_es_f  \\\n",
       "0        4.0  ...    7.0    6.0     5.0     7.0     6.0    2.0         4.0   \n",
       "1        4.0  ...    4.0    6.0     3.0     6.0     4.0    2.0         3.0   \n",
       "2        4.0  ...    7.0    8.0     9.0     8.0     7.0    1.0         0.0   \n",
       "3        4.0  ...    5.0    8.0     7.0     6.0     7.0    2.0         2.0   \n",
       "4        4.0  ...    2.0    2.0     2.0     7.0     5.0    2.0         0.0   \n",
       "...      ...  ...    ...    ...     ...     ...     ...    ...         ...   \n",
       "4179     1.0  ...    2.0    6.0     5.0     6.0     1.0    0.0         2.0   \n",
       "4180     1.0  ...    3.0    7.0     2.0     2.0     2.0    0.0         0.0   \n",
       "4181     1.0  ...    2.0    2.0     1.0     2.0     1.0    0.0         2.0   \n",
       "4182     1.0  ...    5.0    3.0     6.0     6.0     4.0    0.0         4.0   \n",
       "4183     1.0  ...    7.0    7.0     7.0     8.0     5.0    0.0         6.0   \n",
       "\n",
       "      satis_2_f  you_call_f  them_cal_f  \n",
       "0       6.00000    1.000000    1.000000  \n",
       "1       5.00000    0.000000    0.000000  \n",
       "2       5.71151    0.780825    0.981631  \n",
       "3       4.00000    0.000000    0.000000  \n",
       "4       7.00000    0.000000    0.000000  \n",
       "...         ...         ...         ...  \n",
       "4179    3.00000    0.000000    1.000000  \n",
       "4180    5.00000    0.780825    0.981631  \n",
       "4181    4.00000    0.000000    0.000000  \n",
       "4182    5.00000    0.000000    0.000000  \n",
       "4183    8.00000    0.000000    0.000000  \n",
       "\n",
       "[4184 rows x 46 columns]"
      ]
     },
     "execution_count": 651,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_df = pd.merge(df_male, df_female, on=['iid', 'iid_f'])\n",
    "my_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 652,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = np.array(my_df.target)\n",
    "data_df = my_df.drop(['target'], axis=1)\n",
    "data = np.array(data_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разбейте датасет на трейн и валидацию. Подберите на валидации оптимальный критерий  информативности. \n",
    "Постройте графики зависимости точности на валидации от глубины дерева, от минимального числа объектов для сплита. \n",
    "Какой максимальной точности удалось достигнуть?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 653,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.1, stratify=target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 654,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 654,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_clf = MyDecisionTreeClassifier(max_depth=6, min_samples_split=2, min_Q_split=0.00001, feature_linspace=50, criterion='entropy')\n",
    "my_clf.fit(X_train, y_train)\n",
    "y_pred = my_clf.predict(X_test)\n",
    "roc_auc_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 637,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: (0, 31, 0.0),\n",
       " 1: (0, 11, 0.0),\n",
       " 3: (1, 1, 1.0),\n",
       " 4: (1, 0, 1.0),\n",
       " 2: (1, 0, 1.0)}"
      ]
     },
     "execution_count": 637,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_clf.tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 638,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dec', 'dec_f']"
      ]
     },
     "execution_count": 638,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_id, values = my_clf.get_feature_importance()\n",
    "col_names = data_df.columns\n",
    "best_features = list(map(lambda x: col_names[x], features_id))\n",
    "best_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как и следовало ожидать, пользуясь столбцами dec и dec_f которые отвечают за решение (yes/no) каждого из партнеров, можно выбить скор равный 1, так как целевая переменная match является логическим И переменных отвечающих за решение каждого партнера.\n",
    "\n",
    "Наверняка такое решение не предполагалось, поэтому исключу столбцы dec и dec_f как слишком нечестные и повторю эксперимент.\n",
    "Очевидно если использовать их, то они будут самыми важными и score модели будет гораздо выше. Если оставить хоть один из них, то другие параметры, которые характеризуют отношение человека к партнеру будут не важны, так как мы уже знаем его решение."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 639,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = np.array(my_df.target)\n",
    "data_df = my_df.drop(['target', 'dec', 'dec_f'], axis=1)\n",
    "data = np.array(data_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подберу критерий информативности и высоту дерева на кросс-валидации с использованием метрики ROC-AUC. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 640,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, make_scorer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CRITERION: error , SCORE: 0.6510448926655051\n",
      "CRITERION: gini , SCORE: 0.6510448926655051\n",
      "CRITERION: entropy , SCORE: 0.6510448926655051\n"
     ]
    }
   ],
   "source": [
    "criterion = ['error', 'gini', 'entropy'] \n",
    "arr = []\n",
    "\n",
    "for c in criterion:\n",
    "    my_clf = MyDecisionTreeClassifier(max_depth=5, min_samples_split=2,\\\n",
    "                                          min_Q_split=0.00001, feature_linspace=50, criterion=c)\n",
    "    my_clf.fit(X_train, y_train)\n",
    "    score = cross_val_score(my_clf, data, target, cv=5, scoring=make_scorer(roc_auc_score)).mean()\n",
    "    print(\"CRITERION:\", c, \", SCORE:\", score)\n",
    "    arr.append(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как мы видим, все критерии информативности дают одинаковый результат, так что особой роли этот выбор не играет.\n",
    "Я возьму энтропийный критерий в качестве критерия информативности.\n",
    "\n",
    "Далее подберем оптимальную максимальную высоту дерева, так же на кросс-валидации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEPTH: 1 , SCORE: 0.5532602454277838\n",
      "DEPTH: 2 , SCORE: 0.5937788113210342\n",
      "DEPTH: 3 , SCORE: 0.6401252290466715\n",
      "DEPTH: 4 , SCORE: 0.6439850151004898\n",
      "DEPTH: 5 , SCORE: 0.6622004423447623\n",
      "DEPTH: 6 , SCORE: 0.6446308878707835\n",
      "DEPTH: 7 , SCORE: 0.6372366794155045\n",
      "DEPTH: 8 , SCORE: 0.637343805905609\n"
     ]
    }
   ],
   "source": [
    "depth = [1, 2, 3, 4, 5, 6, 7, 8]\n",
    "arr = []\n",
    "\n",
    "for d in depth:\n",
    "    my_clf = MyDecisionTreeClassifier(max_depth=d, min_samples_split=2,\\\n",
    "                                          min_Q_split=0.00001, feature_linspace=50, criterion='entropy')\n",
    "    my_clf.fit(X_train, y_train)\n",
    "    score = cross_val_score(my_clf, data, target, cv=3, scoring=make_scorer(roc_auc_score)).mean()\n",
    "    print(\"DEPTH:\", d, \", SCORE:\", score)\n",
    "    arr.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x15d6f15dc40>]"
      ]
     },
     "execution_count": 503,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(16,5))\n",
    "plt.plot(depth, arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видно из графика оптимальная максимальная высота дерева 5. Её и возьму для финальной модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N_SAMPLES: 1 , SCORE: 0.6622004423447623\n",
      "N_SAMPLES: 2 , SCORE: 0.6622004423447623\n",
      "N_SAMPLES: 5 , SCORE: 0.6612904829593719\n",
      "N_SAMPLES: 10 , SCORE: 0.659476041524321\n",
      "N_SAMPLES: 25 , SCORE: 0.6545354719532245\n",
      "N_SAMPLES: 50 , SCORE: 0.652701495951353\n",
      "N_SAMPLES: 75 , SCORE: 0.6426122093878486\n",
      "N_SAMPLES: 100 , SCORE: 0.6419040158249496\n"
     ]
    }
   ],
   "source": [
    "n_samples = [1, 2, 5, 10, 25, 50, 75, 100]\n",
    "arr = []\n",
    "\n",
    "for n in n_samples:\n",
    "    my_clf = MyDecisionTreeClassifier(max_depth=5, min_samples_split=n,\\\n",
    "                                          min_Q_split=0.00001, feature_linspace=50, criterion='entropy')\n",
    "    my_clf.fit(X_train, y_train)\n",
    "    score = cross_val_score(my_clf, data, target, cv=3, scoring=make_scorer(roc_auc_score)).mean()\n",
    "    print(\"N_SAMPLES:\", n, \", SCORE:\", score)\n",
    "    arr.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x15d6f8b2e20>]"
      ]
     },
     "execution_count": 623,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(16,5))\n",
    "plt.plot(depth, arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Исходя из результатов кросс-валидации оставлю минимальное число объектов для сплита равным 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сравню результаты моей модели с sklearn реализацией и всеми нулями."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 642,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALL ZEROS ACCURACY: 0.8353221957040573\n",
      "SKLEARN ACCURACY SCORE: 0.8233890214797136\n",
      "MY ACCURACY SCORE: 0.8591885441527446\n",
      "\n",
      "SKLEARN ROC-AUC SCORE: 0.6806702282661486\n",
      "MY ROC-AUC SCORE: 0.7567343555739743\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.1, stratify=target)\n",
    "my_clf = MyDecisionTreeClassifier(max_depth=5, min_samples_split=2,\\\n",
    "                                          min_Q_split=0.00001, feature_linspace=50, criterion='entropy')\n",
    "clf = DecisionTreeClassifier(min_samples_split=2)\n",
    "my_clf.fit(X_train, y_train)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"ALL ZEROS ACCURACY:\", accuracy_score(y_pred=np.zeros(y_test.size), y_true=y_test))\n",
    "print(\"SKLEARN ACCURACY SCORE:\", accuracy_score(y_pred=clf.predict(X_test), y_true=y_test))\n",
    "print(\"MY ACCURACY SCORE:\", accuracy_score(y_pred=my_clf.predict(X_test), y_true=y_test))\n",
    "\n",
    "print(\"\\nSKLEARN ROC-AUC SCORE:\", roc_auc_score(clf.predict(X_test), y_test))\n",
    "print(\"MY ROC-AUC SCORE:\", roc_auc_score(my_clf.predict(X_test), y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Находим самые важные признаки (2 балла)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По построенному дереву  легко понять, какие признаки лучше всего помогли решить задачу. Часто это бывает нужно  не только  для сокращения размерности в данных, но и для лучшего понимания прикладной задачи. Например, Вы хотите понять, какие признаки стоит еще конструировать -- для этого нужно понимать, какие из текущих лучше всего работают в дереве. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Самый простой метод -- посчитать число сплитов, где использовался данные признак. Это не лучший вариант, так как по признаку который принимает всего 2 значения, но который почти точно разделяет выборку, число сплитов будет очень 1, но при этом признак сам очень хороший. \n",
    "В этом задании предлагается для каждого признака считать суммарный gain (в лекции обозначено как Q) при использовании этого признака в сплите. Тогда даже у очень хороших признаков с маленьким число сплитов это значение должно быть довольно высоким.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализовать это довольно просто: создаете словарь номер фичи : суммарный гейн и добавляете в нужную фичу каждый раз, когда используете ее при построении дерева. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавьте функционал, который определяет значения feature importance. Обучите дерево на датасете Speed Dating Data.\n",
    "Выведите 10 главных фичей по важности."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Для того чтобы определить самые важные признаки, проведу множество испытаний и посмотрю какие признаки были в среднем самыми значимыми за все испытания."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEAN ACCURACY SCORE: 0.8512171837708832\n",
      "MEAN ROC-AUC SCORE: 0.7331642727801722\n"
     ]
    }
   ],
   "source": [
    "N = 50\n",
    "\n",
    "importance = np.zeros(data.shape[1])\n",
    "roc_auc_score_ = np.zeros(N)\n",
    "accuracy_score_ = np.zeros(N)\n",
    "\n",
    "for i in range(N):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.1, stratify=target)\n",
    "    my_clf = MyDecisionTreeClassifier(max_depth=5, min_samples_split=10,\\\n",
    "                                          min_Q_split=0.00001, feature_linspace=50, criterion='entropy')\n",
    "    my_clf.fit(X_train, y_train)\n",
    "    roc_auc_score_[i] = roc_auc_score(my_clf.predict(X_test), y_test)\n",
    "    accuracy_score_[i] = accuracy_score(my_clf.predict(X_test), y_test)\n",
    "    features_id, values = my_clf.get_feature_importance()\n",
    "    for i in range(features_id.shape[0]):\n",
    "        importance[features_id[i]] += values[i]\n",
    "        \n",
    "print(\"MEAN ACCURACY SCORE:\", accuracy_score_.mean())\n",
    "print(\"MEAN ROC-AUC SCORE:\", roc_auc_score_.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 643,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['attr_f',\n",
       " 'them_cal_f',\n",
       " 'fun_f',\n",
       " 'prob',\n",
       " 'like',\n",
       " 'like_f',\n",
       " 'age_f',\n",
       " 'int_corr',\n",
       " 'attr',\n",
       " 'match_es',\n",
       " 'age',\n",
       " 'iid',\n",
       " 'shar',\n",
       " 'imprace',\n",
       " 'fun',\n",
       " 'match_es_f',\n",
       " 'shar_f',\n",
       " 'intel',\n",
       " 'diff_age',\n",
       " 'prob_f',\n",
       " 'amb',\n",
       " 'intel_f',\n",
       " 'imprelig',\n",
       " 'sinc',\n",
       " 'satis_2',\n",
       " 'exphappy_f',\n",
       " 'you_call',\n",
       " 'amb_f',\n",
       " 'imprace_f',\n",
       " 'date_f',\n",
       " 'sinc_f',\n",
       " 'go_out_f',\n",
       " 'satis_2_f',\n",
       " 'date',\n",
       " 'go_out',\n",
       " 'you_call_f',\n",
       " 'them_cal',\n",
       " 'exphappy',\n",
       " 'iid_f',\n",
       " 'imprelig_f',\n",
       " 'met',\n",
       " 'met_f',\n",
       " 'samerace']"
      ]
     },
     "execution_count": 643,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = np.argsort(importance)[::-1]\n",
    "col_names = data_df.columns\n",
    "f = []\n",
    "for idx in features:\n",
    "    f.append(col_names[idx])\n",
    "\n",
    "f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно заметить, что \"парные\" признаки, такие как like like_f, attr attr_f, имеют зачастую близкую важность, что логично, так как они показывают одни и те же характеристики, просто со стороны разных партнеров (парня и девушки соответственно). Выбирая 10 самых важных признаков такие пары буду объединять в один признак, чтобы получить более полную картину. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В итоге 10 самых важных признаков по мнению моего алгоритма: \n",
    "\n",
    "'attr' - оценка внешности\n",
    "\n",
    "'them_cal' - сколько человек из попаданий (match) предложили провести свидание \n",
    "\n",
    "'fun' - оценка \"весёлости\" \n",
    "\n",
    "'prob' - оценка человеком вероятности того, что решение партнера было положительным\n",
    "\n",
    "'like' - насколько партнеры понравились друг другу.\n",
    "\n",
    "'age' - возраст \n",
    "\n",
    "'int_corr' - корреляция интересов\n",
    "\n",
    "'match_es' - сколько попаданий (match) произошло по мнению человека\n",
    "\n",
    "'iid' - идентификатор человека\n",
    "\n",
    "'shar' - оценка общих интересов\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Фидбек (бесценно)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Какие аспекты обучения деревьев решений Вам показались непонятными? Какое место стоит дополнительно объяснить?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Осталась не до конца понятна обработка категориальных признаков. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ваш ответ здесь"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Здесь Вы можете оставить отзыв о этой домашней работе или о всем курсе."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ВАШ ОТЗЫВ ЗДЕСЬ\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
